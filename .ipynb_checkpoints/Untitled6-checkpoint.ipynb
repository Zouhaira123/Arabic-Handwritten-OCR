{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4092688-5045-49c5-b2fa-b2d7fdfb4e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "460bdbf6-1b2e-4ffa-8686-6750a789ca88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39299 images belonging to 47 classes.\n",
      "Found 9802 images belonging to 47 classes.\n",
      "Found 20659 images belonging to 47 classes.\n"
     ]
    }
   ],
   "source": [
    "# Définir la taille des images en entrée\n",
    "img_rows, img_cols = 224, 224\n",
    "\n",
    "# Chemins des données d'entraînement et de test\n",
    "train_data_dir = 'C:/Users/rihab/Downloads/IFHCDB/Train'\n",
    "test_data_dir = 'C:/Users/rihab/Downloads/IFHCDB/Test'\n",
    "\n",
    "# Définition du générateur d'images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)  # 80% pour l'entraînement, 20% pour la validation\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=128,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=128,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=128,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7fd4155-bc2d-4f6d-becb-f4868c042f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du modèle AlexNet\n",
    "model = Sequential()\n",
    "\n",
    "# Première couche de convolution\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Deuxième couche de convolution\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Troisième couche de convolution\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Couche de flatten\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "\n",
    "# Couche de sortie\n",
    "model.add(Dense(47))  # Nombre de classes\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compiler le modèle\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933bef80-9e6d-48a0-af10-2638c3417fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 49/307 [===>..........................] - ETA: 59:22 - loss: 3.2615 - accuracy: 0.1223"
     ]
    }
   ],
   "source": [
    "# Définir le nombre d'étapes par époque\n",
    "train_steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
    "val_steps_per_epoch = validation_generator.samples // validation_generator.batch_size\n",
    "\n",
    "# Entraîner le modèle\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    epochs=10,  # Nombre d'époques\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=val_steps_per_epoch\n",
    ")\n",
    "\n",
    "# Visualisation des courbes d'apprentissage\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1732002-ee76-4409-9a21-3dc0c531f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Évaluer le modèle sur le jeu de test\n",
    "predictions = model.predict(test_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Afficher la matrice de confusion\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a1549f-621f-405c-99b3-6f194ffe1550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer l'accuracy\n",
    "accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "print(\"Accuracy :\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643ec65f-9dc5-4030-b4f2-265955751c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le résumé du modèle\n",
    "model.summary()\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
